{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pylab import rcParams\n",
    "import statsmodels.api as sm\n",
    "from fbprophet import Prophet\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from pmdarima.arima import auto_arima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Read the csv file *RetailNZ.csv*.\n",
    "Open the dataset by reading the csv file in a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df = pd.read_csv('RetailNZ.csv', sep = ',')\n",
    "retail_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks**:\n",
    "* Convert the *Date* column to date format. \n",
    "* Sort by date\n",
    "* Set the date as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df[\"Time\"] = pd.to_datetime(retail_df[\"Time\"], format = '%Y-%m')  # converting date\n",
    "retail_df = retail_df.sort_values(by = 'Time')  # sorting\n",
    "retail_df = retail_df.set_index('Time')  # indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: We're going to start by only looking at the Clothing data.\n",
    "\n",
    "you can also try to use other time series\n",
    "* 'Footwear'\n",
    "* 'Chemist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_key = 'Clothing'\n",
    "#data_key = 'Chemist'\n",
    "#data_key = 'Footwear'\n",
    "df = retail_df[[data_key]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks**: plot the data using a line chart\n",
    "\n",
    "What is the general trend noticed and what are the visible patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 7.5]\n",
    "df.plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's zoom a bit, for the most recent years. Can you see some visible patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[-36:].plot.line()  # we take the last 36 months -> 3 years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks**: we'll try to get rid of seasonality & trend by differencing\n",
    "\n",
    "First, let's see if differencing with previous element works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.diff().plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It removed the trend, but seasonality stayed. How about differencing with the element 12months ago?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.diff(periods=12).plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our observations using autocorrelation & partial autocorrelation\n",
    "\n",
    "**Tasks**: plot the autocorrelation and partial autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(df, lags=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(df, lags=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will deconstruct the time series into several components. Each component represents a category of patterns. This step is called **time series decomposition**.\n",
    "\n",
    "**Tasks**: Decompose the time serie and understand the underlying concept of:\n",
    "* Trend\n",
    "* Seasonality\n",
    "* Residuals also called noise or randomness\n",
    "\n",
    "_Pay attention to the scale of the graphs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to change the 'model' parameter to multiplicative to see the difference\n",
    "decomposition = sm.tsa.seasonal_decompose(df, model='additive')\n",
    "fig = decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this exercise, we're going to keep years 1995-2007 for training, and try to predict years 2008,2009 and 2010. We will then verify our predictions against the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[:-36]  # trainset is from first data point to the last data point minus 36 (months)\n",
    "test = df[-36:]  # testset is from last data point minue 36 months to the end\n",
    "\n",
    "train.index = pd.to_datetime(train.index)\n",
    "test.index = pd.to_datetime(test.index)\n",
    "\n",
    "ground_truth = test.copy()\n",
    "\n",
    "def mape(true_series: pd.core.series.Series, pred_series: pd.core.series.Series):\n",
    "    # Mean absolute percentage error\n",
    "    y_true, y_hat = true_series.values, pred_series.values\n",
    "    return 100. * np.mean(np.abs((y_true - y_hat) / y_true))\n",
    "\n",
    "\n",
    "def mase(true_series: pd.core.series.Series, pred_series: pd.core.series.Series):\n",
    "    # Mean absolute scaled error\n",
    "    y_true, y_hat = true_series.values, pred_series.values\n",
    "    errors = np.sum(np.abs(y_true - y_hat))\n",
    "    t = y_true.size\n",
    "    scale = t/(t-1) * np.sum(np.abs(np.diff(y_true, axis=0)))\n",
    "    \n",
    "    return errors / scale\n",
    "\n",
    "def plot_result(train, ground_truth, predictions, title=None):\n",
    "    plt.plot(train,lw=2, label='train')\n",
    "    plt.plot(ground_truth,lw=2, label='true')\n",
    "    plt.plot(predictions, label='prediction')\n",
    "    plt.title((title or '') + ' MAPE=' + str(mape(ground_truth, predictions)))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exponential smoothing** makes predictions based on past observations, but over time the weights are assigned exponentially decreasing values.\n",
    "\n",
    "**Tasks**:\n",
    "* Instantiate and exponential smoothing model\n",
    "* train it (fit)\n",
    "* plot the predictions and the groundtruth\n",
    "* Try to put the seasonal_period to 11, why is it an important argument ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExponentialSmoothing(train.values, seasonal_periods = 12, seasonal = 'add', trend = 'add', damped=False)\n",
    "fit = model.fit()\n",
    "exp_forecast = pd.Series(fit.forecast(36))\n",
    "exp_forecast.index = pd.to_datetime(test.index)\n",
    "plot_result(train, ground_truth, exp_forecast, title = 'Exponential Smoothing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ets() from R by rpy2 package\n",
    "\n",
    "R language provide a lot of libraries including all the most famous forecasting models\n",
    "rpy2 is a package that allows us to run methods from R packages throug Python.\n",
    "\n",
    "It is useful to know this trick since R provide more built-in models than Python.\n",
    "\n",
    "Let's try to train an Exponential Smoothing model using wrapped R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Any\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from rpy2.robjects import r, pandas2ri\n",
    "from rpy2.robjects.vectors import IntVector, FloatVector\n",
    "forecast = importr(\"forecast\")\n",
    "rstats = importr('stats')\n",
    "\n",
    "def ets(time_series: pd.core.series.Series, h: int, start: int = 1, frequency: int = 12) -> Tuple[np.ndarray, Any]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        time_series (pd.core.series.Series): time series\n",
    "        h (int): the horizon (how many prediction do we want)\n",
    "        start (int): time of first observation\n",
    "        frequency (int): the number of observations per unit time (1: annual, 4: quartly, 12: monthly, ...)\n",
    "    Returns:\n",
    "        numpy.ndarray: array with predictions\n",
    "        Any: R object with predictions details\n",
    "    \"\"\"\n",
    "    time_series_r = rstats.ts(FloatVector(time_series.values), start=start, frequency=frequency)\n",
    "    result = forecast.forecast(forecast.ets(time_series_r, allow_multiplicative_trend=True), h=h)\n",
    "    preds = np.asarray(result[1])\n",
    "    return preds, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, ets_model = ets(train, h=36)\n",
    "ets_forecast = pd.Series(preds)\n",
    "ets_forecast.index = pd.to_datetime(test.index)\n",
    "plot_result(train, ground_truth, ets_forecast, title = 'ETS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ets_model  # print some of the internals parameters of the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About seasonality: ARIMA and SARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't account for seasonality, we will only get predictions that take into account the general trend.\n",
    "\n",
    "* Autoregressive (AR),\n",
    "* Moving Average (MA),\n",
    "* Autoregressive Moving Average (ARMA),\n",
    "* Autoregressive Integrated Moving Average (ARIMA)\n",
    "* Seasonal Autoregressive Integrated Moving Average (SARIMA)\n",
    "\n",
    "ARIMA and ARIMA, both are Autoregressive models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(train.values, order=(5,1,0)) # check with (12,0,0)\n",
    "fitarima = model.fit()\n",
    "arima_forecast = pd.Series(fitarima.forecast(36)[0])\n",
    "arima_forecast.index = pd.to_datetime(test.index)\n",
    "plot_result(train, ground_truth, arima_forecast, title = 'ARIMA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SARIMA (Seasonal Autoregressive Integrated Moving Average)** - we will now take into account that there is a visible yearly pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_SARIMAX = SARIMAX(train.values, order = (2,0,0), seasonal_order = (2,0,1,12), enforce_stationarity=False)\n",
    "fitsarima = model_SARIMAX.fit()\n",
    "sarimax_forecast = pd.Series(fitsarima.forecast(36))\n",
    "sarimax_forecast.index = pd.to_datetime(test.index)\n",
    "plot_result(train, ground_truth, sarimax_forecast, title = 'SARIMAX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Auto ARIMA** - we will now try to use automated version of best ARIMA fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autoarima = auto_arima(train.values, seasonal=True, m=12, suppress_warnings=True)\n",
    "pred = model_autoarima.predict(n_periods=36)\n",
    "autoarima_forecast = pd.Series(pred)\n",
    "autoarima_forecast.index = pd.to_datetime(test.index)\n",
    "plot_result(train, ground_truth, autoarima_forecast, title = 'Auto ARIMA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Evaluate models\n",
    "\n",
    "We can use different metrics to evaluate the performances of our models, for instance\n",
    "\n",
    "* MAPE (Mean Absolute Percentage Error)\n",
    "* MASE (Mean Absolute Scaled Error)\n",
    "\n",
    "**Tasks**: compute MAPE and MASE to compare SARIMA and Exponential Smoothing\n",
    "Which one is the best?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"Exponential Smoothing\", \"AutoARIMA\", \"ETS\", \"SARIMAX\"]\n",
    "predictions = [exp_forecast, autoarima_forecast, ets_forecast, sarimax_forecast]\n",
    "metrics = [\"MAPE\", \"MASE\"]\n",
    "eval_funcs = [mape, mase]\n",
    "for model_label, pred in zip(models, predictions):\n",
    "    for metric, eval_func in zip(metrics, eval_funcs):\n",
    "        print(\"Model: {}, Metric: {}, Value: {}\".format(model_label, metric, eval_func(ground_truth, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: try taking a look at the data for *Chemist* or *Footwear* and see how the seasonal patterns change and how adjusting the parameters can change your results.\n",
    "\n",
    "Go back to the top of the notebook to change what time serie is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
