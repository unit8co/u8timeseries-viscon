{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "from u8timeseries import Prophet, KthValueAgoBaseline, ExponentialSmoothing, TimeSeries, Arima, AutoArima\n",
    "from u8timeseries import StandardRegressiveModel\n",
    "from u8timeseries.metrics import mape, overall_percentage_error, mase\n",
    "from u8timeseries.backtesting import simulate_forecast_ar, simulate_forecast_regr, get_train_val_series, backtest_autoregressive_model\n",
    "\n",
    "import pandas as pd\n",
    "pd.__version__\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Ensembling and Backtesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Create a **TimeSeries** from a pandas dataframe loading the retailNz dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_key = 'Chemist' # or 'Chemist' or 'Footwear'\n",
    "df = pd.read_csv('RetailNZ.csv', sep = ',')\n",
    "series = TimeSeries.from_dataframe(df, 'Time', data_key) # we ca explicitely give what column contains values\n",
    "series.plot(lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a series of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_es = ExponentialSmoothing()\n",
    "model_pr = Prophet()\n",
    "model_ar = AutoArima()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to perform predictions starting 2007.\n",
    "\n",
    "**Task**: try one of these models and plot the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = series.split_after(pd.Timestamp('20070101'))\n",
    "model_es.fit(train)\n",
    "pred = model_es.predict(len(val))\n",
    "\n",
    "train.plot(lw=2, label='train')\n",
    "val.plot(lw=2, label='true')\n",
    "pred.plot(lw=2, label='prediction')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll do some backtesting, which means that we will simulate predictions that would have been done historically with a given model.\n",
    "\n",
    "We are going to simulate forecasts for 6 months in the future, and this number of time steps is called **forecast horizon**.\n",
    "\n",
    "The model is refit every 6 month with previous step forecast horizon as training data, so this will take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_fcast = simulate_forecast_ar(series, model_es, pd.Timestamp('20070101'), fcast_horizon_n=6, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "series.plot(label='data')\n",
    "historical_fcast.plot(lw=3, label='Backtest 6-months ahead forecast')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtest the models on the data using a user-defined metric\n",
    "Here we'll do slightly more advanced backtesting, and use our own metric (in this case the MAPE error function) to compare the different models. We'll simulate 12-months ahead predictions done in the past, starting in January 1955, and the errors will be computed on the 12-months period for which forecasts are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_model(model, series):\n",
    "    tic = time.time()\n",
    "    train_val_series = get_train_val_series(series, start=pd.Timestamp('20070101'), nr_points_val=12)\n",
    "    res = backtest_autoregressive_model(model, train_val_series, mape)\n",
    "    tac = time.time()\n",
    "    print('Backtest done in %.2f s.' % (tac-tic))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ar = backtest_model(model_ar, series)\n",
    "res_pr = backtest_model(model_pr, series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the user-defined backtesting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(res_ar, bins=50, cumulative=True, histtype='step', \n",
    "         lw=2, label='AutoARIMA');\n",
    "plt.hist(res_pr, bins=50, cumulative=True, histtype='step', \n",
    "         lw=2, label='Prophet');\n",
    "\n",
    "plt.xlabel('Mean absolute percentage error (%)')\n",
    "plt.ylabel('CDF')  # Cumulative distribution function\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: based on the results, use the best performing model to make an actual forecast, for 3 years ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ar.fit(series)\n",
    "pred = model_ar.predict(n = 36)\n",
    "\n",
    "series.plot(label='data', lw=2)\n",
    "pred.plot(label='forecast', lw=2)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling several predictions\n",
    "Let's simulate forecasts done by an ensemble of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, backtest over time using the models you want to use in the ensemble method.\n",
    "We backtest over a forecast horizon of 6 months from 2007."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [Prophet(), AutoArima()]\n",
    "\n",
    "historical_ar_preds = [simulate_forecast_ar(series, m, pd.Timestamp('20070101'), fcast_horizon_n=6, verbose=True)\n",
    "                       for m in models]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the individual simulated predictions. A regressive model in contrary to an auto regressive model doesn't forecast based on the previous values of the series but based on a set of features data points.\n",
    "\n",
    "In this example we will use the StandardRegressiveModel which is a Linear Regression, the features are the predictions made by backtesting and the Linear Regression model will be trained on 12 points (12 pairs of predictions).\n",
    "\n",
    "In other hand it will learn the optimal weights such as the weighted average of predictions is the closest to the groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regrModel = StandardRegressiveModel(train_n_points=12)\n",
    "\n",
    "series_val = series.intersect(historical_ar_preds[0])\n",
    "\n",
    "historical_pred = simulate_forecast_regr(historical_ar_preds, series_val, regrModel,\n",
    "                                         pd.Timestamp('20080101'), fcast_horizon_n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute errors and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "series.plot()\n",
    "for i, m in enumerate(models):\n",
    "    historical_ar_preds[i].plot(label=str(m))\n",
    "    \n",
    "    # intersect last part, to compare everything with ensemble\n",
    "    ar_pred = historical_ar_preds[i].intersect(historical_pred)\n",
    "       \n",
    "    mape_er = mape(series.intersect(historical_pred), ar_pred)\n",
    "    print('MAPE Error {}: {}'.format(m, mape_er))\n",
    "\n",
    "print('MAPE Error ensemble: {}'.format(mape(series.intersect(historical_pred), historical_pred)))\n",
    "\n",
    "historical_pred.plot(label='Ensemble')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
